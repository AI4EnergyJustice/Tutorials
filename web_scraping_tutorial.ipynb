{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc93fa64",
   "metadata": {},
   "source": [
    "\n",
    "# Web Scraping Tutorial\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to Web Scraping](#introduction)\n",
    "2. [Web Scraping Ethics and Legal Considerations](#ethics)\n",
    "3. [Python Libraries for Web Scraping](#libraries)\n",
    "4. [Setting up the Environment](#setup)\n",
    "5. [Basics of HTML](#html)\n",
    "6. [Using Beautiful Soup to Parse HTML](#beautifulsoup)\n",
    "7. [Example Project: Scraping a Simple Webpage](#example)\n",
    "\n",
    "---\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da41eae",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Introduction to Web Scraping <a name=\"introduction\"></a>\n",
    "\n",
    "Web scraping is a method used to extract data from websites. This is done by making a request to the web server for the page's HTML, which is then parsed to extract the desired data. Web scraping is often used for data mining, data analysis, testing, and many other applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a116b",
   "metadata": {},
   "source": [
    "## 2. Web Scraping Ethics and Legal Considerations <a name=\"ethics\"></a>\n",
    "\n",
    "Before starting a web scraping project, it's important to understand the ethical\n",
    "and legal considerations. Not all websites allow web scraping, and even when\n",
    "they allow, they have certain limitations about the rate of scraping. Please\n",
    "also note that data you scraped may be protected by copyright. Always check a website's \"robots.txt\" file and\n",
    "terms of service before scraping.\n",
    "\n",
    "Web scraping is a powerful tool for extracting data from websites. However, it's important to consider the ethical and legal implications before starting a web scraping project. Here is a simple guide to help you navigate these considerations.\n",
    "\n",
    "#### Respect Copyright Laws\n",
    "\n",
    "Web content is often protected by copyright laws. Using this content without permission can lead to legal consequences. Always ensure that the data you are scraping is not copyrighted, or that you have permission to use it.\n",
    "\n",
    "#### Read the Terms of Service\n",
    "\n",
    "Before scraping a website, make sure to read its Terms of Service (ToS). Some websites explicitly forbid web scraping in their ToS. Disregarding this can lead to being banned from the site or even legal action.\n",
    "\n",
    "#### Respect Robots.txt\n",
    "\n",
    "`Robots.txt` is a file used by websites to guide how search engines crawl their pages. It can also provide guidance on which parts of the site the owners prefer not to be scraped. While not legally binding, it's considered good web etiquette to respect the instructions in `robots.txt`.\n",
    "\n",
    "#### Don't Overload the Server\n",
    "\n",
    "Sending too many requests to a website in a short amount of time can overload the server, which can slow down or disrupt service for other users. Be considerate of how many requests you send and try to limit your scraping to off-peak times.\n",
    "\n",
    "#### Be Aware of Privacy Issues\n",
    "\n",
    "Be mindful of privacy issues when scraping personal data. Laws such as the European General Data Protection Regulation (GDPR) or the California Consumer Privacy Act (CCPA) have strict rules about how personal data can be collected and used.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Web scraping is a powerful tool, but it's important to use it responsibly. Always respect the legal rights and privacy of others, and strive to minimize your impact on the services you scrape.\n",
    "\n",
    "Remember, this guide is not legal advice, and laws may vary by location and over\n",
    "time. If you're unsure about the legality of your web scraping project, it's\n",
    "always a good idea to consult with a legal expert.\n",
    "\n",
    "## 3. Python Libraries for Web Scraping <a name=\"libraries\"></a>\n",
    "\n",
    "There are many libraries available in Python to perform web scraping. Some of the most commonly used ones are:\n",
    "\n",
    "- **Requests**: This library allows you to send HTTP requests and handle the response in Python.\n",
    "\n",
    "- **Beautiful Soup**: This library is used for parsing HTML and XML documents. It creates a parse tree from page source code that can be used to extract data in a hierarchical and readable manner.\n",
    "\n",
    "- **Selenium**: Selenium is mainly used for testing in the industry, but it can also be used for web scraping. It provides a way to control a web browser with code, which is useful for interacting with JavaScript-based websites.\n",
    "\n",
    "- **Scrapy**: Scrapy is a powerful and versatile web scraping library, but it can be a bit complex for beginners. It's used for more extensive web scraping projects.\n",
    "\n",
    "In this tutorial, we'll be focusing on using the `requests` and `Beautiful Soup` libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7e8b2",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Setting up the Environment <a name=\"setup\"></a>\n",
    "\n",
    "Before we start coding, we need to install the necessary libraries. This can be done by running the following commands in your Jupyter notebook:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e61fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c39ca1",
   "metadata": {},
   "source": [
    "\n",
    "You can import the necessary libraries at the start of your notebook and print\n",
    "their versions. This can help while debugging a problem. \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0044d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "print('Python version')\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea248fd",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Basics of HTML <a name=\"html\"></a>\n",
    "\n",
    "HTML (HyperText Markup Language) is the standard markup language for creating web pages. It uses tags to define elements, which are the building blocks of web pages. Understanding HTML is essential for web scraping because it allows us to understand the structure of the web page and identify the data we want to extract.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7cd9a6",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Using Beautiful Soup to Parse HTML <a name=\"beautifulsoup\"></a>\n",
    "\n",
    "Beautiful Soup is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files. It creates a parse tree from page source code that can be used to extract data in a hierarchical and readable manner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa64a6",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Example Project: Wikipedia\n",
    "\n",
    "Let's try scraping the Wikipedia page describing high-performance computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce49256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      "\n",
      "\n",
      "\n",
      "High-performance computing - Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jump to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\t\tNavigation\n",
      "\t\n",
      "\n",
      "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tContribute\n",
      "\t\n",
      "\n",
      "HelpLearn to editCommunity portalRecent changesUpload file\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Languages\n",
      "\n",
      "Language links are at the top of the page across from the title.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Create accountLog in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Create account Log in\n",
      "\n",
      "\n",
      "\n",
      "Pages for logged out editors learn more\n",
      "\n",
      "ContributionsTalk\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(Top)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2TOP500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3High performance computing in the cloud\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4See also\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5References\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6External links\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle the table of contents\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle the table of contents\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "High-performance computing\n",
      "\n",
      "\n",
      "\n",
      "18 languages\n",
      "\n",
      "\n",
      "\n",
      "العربيةAsturianuবাংলাČeštinaDanskDeutschEspañolFrançais한국어Italiano日本語PortuguêsShqipSuomiSvenskaไทยTürkçe中文\n",
      "Edit links\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Article\n",
      "\n",
      "Talk\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "English\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Read\n",
      "\n",
      "Edit\n",
      "\n",
      "View history\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tools\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\t\tActions\n",
      "\t\n",
      "\n",
      "ReadEditView history\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tGeneral\n",
      "\t\n",
      "\n",
      "What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageWikidata item\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tPrint/export\n",
      "\t\n",
      "\n",
      "Download as PDFPrintable version\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "From Wikipedia, the free encyclopedia\n",
      "\n",
      "\n",
      "Computing with supercomputers and clusters\n",
      "Not to be confused with high-throughput computing or many-task computing.\n",
      " The Center for Nanoscale Materials at the Advanced Photon Source\n",
      "High-performance computing (HPC) uses supercomputers and computer clusters to solve advanced computation problems. \n",
      "\n",
      "\n",
      "Overview[edit]\n",
      "HPC integrates systems administration (including network and security knowledge) and parallel programming into a multidisciplinary field that combines digital electronics, computer architecture, system software, programming languages, algorithms and computational techniques.[1]\n",
      "HPC technologies are the tools and systems used to implement and create high performance computing systems.[2] Recently[when?], HPC systems have shifted from supercomputing to computing clusters and grids.[1] Because of the need of networking in clusters and grids, High Performance Computing Technologies are being promoted[by whom?] by the use of a collapsed network backbone, because the collapsed backbone architecture is simple to troubleshoot and upgrades can be applied to a single router as opposed to multiple ones.\n",
      "The term is most commonly associated with computing used for scientific research or computational science. A related term, high-performance technical computing (HPTC), generally refers to the engineering applications of cluster-based computing (such as computational fluid dynamics and the building and testing of virtual prototypes). HPC has also been applied to business uses  such as data warehouses, line-of-business (LOB) applications, and transaction processing.\n",
      "High-performance computing (HPC) as a term arose after the term \"supercomputing\".[3] HPC is sometimes used as a synonym for supercomputing; but, in other contexts, \"supercomputer\" is used to refer to a more powerful subset of \"high-performance computers\", and the term \"supercomputing\" becomes a subset of \"high-performance computing\". The potential for confusion over the use of these terms is apparent.\n",
      "Because most current applications are not designed for HPC technologies but are retrofitted, they are not designed or tested for scaling to more powerful processors or machines.[2] Since networking clusters and grids use multiple processors and computers, these scaling problems can cripple critical systems in future supercomputing systems. Therefore, either the existing tools do not address the needs of the high performance computing community or the HPC community is unaware of these tools.[2] A few examples of commercial HPC technologies include:\n",
      "\n",
      "the simulation of car crashes for structural design\n",
      "molecular interaction for new drug design\n",
      "the airflow over automobiles or airplanes\n",
      "In government and research institutions, scientists simulate galaxy creation, fusion energy, and global warming, as well as work to create more accurate short- and long-term weather forecasts.[4] The world's tenth most powerful supercomputer in 2008, IBM Roadrunner (located at the United States Department of Energy's Los Alamos National Laboratory)[5] simulated the performance, safety, and reliability of nuclear weapons and certifies their functionality.[6]\n",
      "\n",
      "TOP500[edit]\n",
      "A list of the most powerful high-performance computers can be found on the TOP500 list. The TOP500 list ranks the world's 500 fastest high-performance computers, as measured by the High Performance LINPACK (HPL) benchmark. Not all computers are listed, either because they are ineligible (e.g., they cannot run the HPL benchmark) or because their owners have not submitted an HPL score (e.g., because they do not wish the size of their system to become public information for defense reasons). In addition, the use of the single LINPACK benchmark is controversial, in that no single measure can test all aspects of a high-performance computer. To help overcome the limitations of the LINPACK test, the U.S. government commissioned one of its originators, Jack Dongarra of the University of Tennessee, to create a suite of benchmark tests that includes LINPACK and others, called the HPC Challenge benchmark suite. This evolving suite has been used in some HPC procurements, but, because it is not reducible to a single number, it has been unable to overcome the publicity advantage of the less useful TOP500 LINPACK test. The TOP500 list is updated twice a year, once in June at the ISC European Supercomputing Conference and again at a US Supercomputing Conference in November.\n",
      "Many ideas for the new wave of grid computing were originally borrowed from HPC.\n",
      "\n",
      "High performance computing in the cloud[edit]\n",
      "Main article: Cloud computing\n",
      "Traditionally, HPC has involved an on-premises infrastructure, investing in supercomputers or computer clusters. Over the last decade, cloud computing has grown in popularity for offering computer resources in the commercial sector regardless of their investment capabilities.[7] Some characteristics like scalability and containerization also have raised interest in academia.[8] However security in the cloud concerns such as data confidentiality are still considered when deciding between cloud or on-premise HPC resources.[7]\n",
      "\n",
      "See also[edit]\n",
      "\n",
      "High-performance technical computing\n",
      "Distributed computing\n",
      "Parallel computing\n",
      "Computational science\n",
      "Quantum computing\n",
      "Metacomputing\n",
      "Supercomputer\n",
      "Grand Challenge\n",
      "High Productivity Computing Systems\n",
      "High-availability cluster\n",
      "High-throughput computing\n",
      "Many-task computing\n",
      "Urgent computing\n",
      "Cloud computing\n",
      "\n",
      "References[edit]\n",
      "\n",
      "\n",
      "^ a b Brazell, Jim; Bettersworth, Michael (2005). High Performance Computing (Report). Texas State Technical College. Archived from the original on 2010-07-31.\n",
      "\n",
      "^ a b c Collette, Michael; Corey, Bob; Johnson, John (December 2004). High Performance Tools & Technologies (PDF) (Report). Lawrence Livermore National Laboratory, U.S. Department of Energy. Archived from the original (PDF) on 2017-08-30.\n",
      "\n",
      "^ \"supercomputing\". Oxford English Dictionary (Online ed.). Oxford University Press. (Subscription or participating institution membership required.) \"Supercomputing\" is attested from 1944.\n",
      "\n",
      "^ Schulman, Michael. \"High Performance Computing: RAM vs CPU\". Dr. Dobbs High Performance Computing, April 30, 2007.\n",
      "\n",
      "^ \"Launching a New Class of U.S. Supercomputing\". Department of Energy. 17 November 2022.\n",
      "\n",
      "^ \"High Performance Computing\". US Department of Energy. Archived from the original on 30 July 2009.\n",
      "\n",
      "^ a b Morgan Eldred; Dr. Alice Good; Carl Adams (24 January 2018). \"A case study on data protection and security decisions in cloud HPC\" (PDF). School of Computing, University of Portsmouth, Portsmouth, U.K.\n",
      "\n",
      "^ Sebastian von Alfthan (2016). \"High-performance computing in the cloud?\" (PDF). CSC – IT Center for Science.\n",
      "\n",
      "\n",
      "External links[edit]\n",
      "HPCwire\n",
      "Top 500 supercomputers\n",
      "Rocks Clusters Open-Source High Performance Linux Clusters\n",
      "News Articles & Policy Reports on High-Performance Scientific Computing\n",
      "The Center for Modeling Immunity to Enteric Pathogens (MIEP)\n",
      "The Art of HPC: Textbooks by Victor Eijkhout of TACC\n",
      "Vol.1: The Science of Computing\n",
      "Vol.2: Parallel Programming for Science Engineering\n",
      "Vol.3: Introduction to Scientific Programming in C++17/Fortran2008\n",
      "Vol.4: Tutorials for High Performance Scientific Computing\n",
      "vteParallel computingGeneral\n",
      "Distributed computing\n",
      "Parallel computing\n",
      "Massively parallel\n",
      "Cloud computing\n",
      "High-performance computing\n",
      "Multiprocessing\n",
      "Manycore processor\n",
      "GPGPU\n",
      "Computer network\n",
      "Systolic array\n",
      "Levels\n",
      "Bit\n",
      "Instruction\n",
      "Thread\n",
      "Task\n",
      "Data\n",
      "Memory\n",
      "Loop\n",
      "Pipeline\n",
      "Multithreading\n",
      "Temporal\n",
      "Simultaneous (SMT)\n",
      "Speculative (SpMT)\n",
      "Preemptive\n",
      "Cooperative\n",
      "Clustered multi-thread (CMT)\n",
      "Hardware scout\n",
      "Theory\n",
      "PRAM model\n",
      "PEM model\n",
      "Analysis of parallel algorithms\n",
      "Amdahl's law\n",
      "Gustafson's law\n",
      "Cost efficiency\n",
      "Karp–Flatt metric\n",
      "Slowdown\n",
      "Speedup\n",
      "Elements\n",
      "Process\n",
      "Thread\n",
      "Fiber\n",
      "Instruction window\n",
      "Array\n",
      "Coordination\n",
      "Multiprocessing\n",
      "Memory coherence\n",
      "Cache coherence\n",
      "Cache invalidation\n",
      "Barrier\n",
      "Synchronization\n",
      "Application checkpointing\n",
      "Programming\n",
      "Stream processing\n",
      "Dataflow programming\n",
      "Models\n",
      "Implicit parallelism\n",
      "Explicit parallelism\n",
      "Concurrency\n",
      "Non-blocking algorithm\n",
      "Hardware\n",
      "Flynn's taxonomy\n",
      "SISD\n",
      "SIMD\n",
      "Array processing (SIMT)\n",
      "Pipelined processing\n",
      "Associative processing\n",
      "MISD\n",
      "MIMD\n",
      "Dataflow architecture\n",
      "Pipelined processor\n",
      "Superscalar processor\n",
      "Vector processor\n",
      "Multiprocessor\n",
      "symmetric\n",
      "asymmetric\n",
      "Memory\n",
      "shared\n",
      "distributed\n",
      "distributed shared\n",
      "UMA\n",
      "NUMA\n",
      "COMA\n",
      "Massively parallel computer\n",
      "Computer cluster\n",
      "Beowulf cluster\n",
      "Grid computer\n",
      "Hardware acceleration\n",
      "APIs\n",
      "Ateji PX\n",
      "Boost\n",
      "Chapel\n",
      "HPX\n",
      "Charm++\n",
      "Cilk\n",
      "Coarray Fortran\n",
      "CUDA\n",
      "Dryad\n",
      "C++ AMP\n",
      "Global Arrays\n",
      "GPUOpen\n",
      "MPI\n",
      "OpenMP\n",
      "OpenCL\n",
      "OpenHMPP\n",
      "OpenACC\n",
      "Parallel Extensions\n",
      "PVM\n",
      "pthreads\n",
      "RaftLib\n",
      "ROCm\n",
      "UPC\n",
      "TBB\n",
      "ZPL\n",
      "Problems\n",
      "Automatic parallelization\n",
      "Deadlock\n",
      "Deterministic algorithm\n",
      "Embarrassingly parallel\n",
      "Parallel slowdown\n",
      "Race condition\n",
      "Software lockout\n",
      "Scalability\n",
      "Starvation\n",
      "\n",
      " Category: Parallel computing\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieved from \"https://en.wikipedia.org/w/index.php?title=High-performance_computing&oldid=1155309679\"\n",
      "Category: Parallel computingHidden categories: Articles with short descriptionShort description is different from WikidataAll articles with vague or ambiguous timeVague or ambiguous time from November 2011Articles with specifically marked weasel-worded phrases from November 2011\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " This page was last edited on 17 May 2023, at 16:03 (UTC).\n",
      "Text is available under the Creative Commons Attribution-ShareAlike License 4.0;\n",
      "additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\n",
      "\n",
      "\n",
      "Privacy policy\n",
      "About Wikipedia\n",
      "Disclaimers\n",
      "Contact Wikipedia\n",
      "Code of Conduct\n",
      "Mobile view\n",
      "Developers\n",
      "Statistics\n",
      "Cookie statement\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle limited content width\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Make a request to the website\n",
    "r = requests.get(\"https://en.wikipedia.org/wiki/High-performance_computing\")\n",
    "r.content\n",
    "\n",
    "# Use the 'html.parser' to parse the page\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "# Extract the text from the page\n",
    "text = soup.get_text()\n",
    "\n",
    "# Extract the URLs from the page\n",
    "urls = []\n",
    "for link in soup.find_all('a'):\n",
    "    urls.append(link.get('href'))\n",
    "\n",
    "# Extract the images from the page\n",
    "images = []\n",
    "for img in soup.find_all('img'):\n",
    "    images.append(img.get('src'))\n",
    "\n",
    "# Print the results\n",
    "print(\"Text:\", text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0459c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.strip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f92bd3",
   "metadata": {},
   "source": [
    "The raw text can be useful, but it is harder to parse since we lost the\n",
    "structure. Could there be a better way to access online content?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ai4energyjustice_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b04364c423c512f1536a27fe426a1c4e4022d4d52be46218bff83eabacc54ea3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
