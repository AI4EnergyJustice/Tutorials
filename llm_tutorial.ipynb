{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cafda9cf",
   "metadata": {},
   "source": [
    "\n",
    "# Large Language Models Tutorial\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Large Language Models](#llms)\n",
    "2. [Using LLMs Programmatically](#api)\n",
    "3. [HuggingFace's Transformers Library](#huggingface)\n",
    "4. [Using LLMs with the Transformers Library](#example)\n",
    "\n",
    "---\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e04d2",
   "metadata": {},
   "source": [
    "## 1. Large Language Models <a name=\"llms\"></a>\n",
    "\n",
    "Large Language Models (LLMs) are artificial intelligence models that\n",
    "have been trained to understand and generate text using human languages. They are based on a\n",
    "type of neural network architecture called transformers, which enables them to\n",
    "process and analyze large amounts of text data. LLMs learn to predict the next\n",
    "word in a sentence by being trained on large amounts of text data, which allows\n",
    "them to generate coherent and contextually relevant sentences. They have been\n",
    "used in a variety of applications, including question answering, text\n",
    "generation, translation, and summarization. What makes them particularly impressive is that they're not specifically programmed for each of these tasks. Instead, they learn patterns and structures from the data they are trained on and apply this knowledge to generate responses. These models are a great example of the power of Machine Learning, demonstrating how machines can learn from data to perform tasks that traditionally require human intelligence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb0c2f",
   "metadata": {},
   "source": [
    "## 2. Accessing LLMs Programmatically <a name=\"api\"></a>\n",
    "\n",
    "Accessing Large Language Models (LLMs) programmatically, as opposed to using a web interface, opens up a vast array of possibilities for their usage and integration into applications. By using a programming interface, you can directly interact with the model in a more flexible and customized manner. This is particularly useful in scenarios where you need to process large amounts of data, automate tasks, or integrate the model into a larger system. For example, you might want to use an LLM to analyze and generate responses to user queries on a website, generate content for a blog, or conduct large-scale analysis of text data. In a Jupyter notebook, you can experiment with the model, fine-tune its parameters, and visualize its outputs in a flexible, interactive environment. Furthermore, by accessing LLMs programmatically, you can leverage the full power and functionality of programming languages like Python, which offer a wide range of libraries and tools for data analysis, machine learning, and more. This approach enables more advanced usage of LLMs, and is a key skill for anyone working in the field of AI and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7afe5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "def chatGPT(prompt, model=\"text-davinci-003\"):\n",
    "    \"\"\"\n",
    "    Generate text using OpenAI's models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prompt : str\n",
    "        The initial text to base the AI's response on.\n",
    "    model : str, optional\n",
    "        The specific OpenAI model to use for the text generation.\n",
    "        Defaults to 'text-davinci-003'.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        The function prints the AI-generated text and the time taken to get the response,\n",
    "        but does not return these values.\n",
    "    \"\"\"\n",
    "\n",
    "    # The endpoint for OpenAI's GPT-3 model\n",
    "    url = \"https://api.openai.com/v1/completions\"\n",
    "\n",
    "    # Retrieve the API key from environment variables\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        api_key = input(\"OPENAI_API_KEY is not defined, please enter it: \")\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "    # Define the headers for the HTTP request\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + api_key,\n",
    "    }\n",
    "\n",
    "    # Define the data for the HTTP request\n",
    "    data = {\n",
    "        \"model\": model,  # Specify the model to use\n",
    "        \"prompt\": prompt,  # The initial text to base the response on\n",
    "        \"max_tokens\": 4000,  # The maximum length of the generated text\n",
    "        \"temperature\": 1.0,  # The randomness of the generated text\n",
    "    }\n",
    "\n",
    "    # Record the time before sending the request\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Send a POST request to the OpenAI API\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    # Record the time after receiving the response\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate the elapsed time (in seconds)\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Extract the generated text from the response\n",
    "    output = response.json()[\"choices\"][0][\"text\"]\n",
    "\n",
    "    # Return both the output text and the elapsed time as strings\n",
    "    return output, f\"Time taken to get the response: {elapsed_time:.3f} seconds\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9067bfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n\\nEnergy justice is the concept of ensuring that everyone has access to clean, affordable, and reliable energy services. It is an attempt to ensure that the burdens and benefits of energy production and systems are fairly distributed and that those who are most affected by decisions related to energy—the marginalized, vulnerable, or disadvantaged—are given a voice in determining how energy is produced and used. It is a broader form of energy democracy, which is the idea that everyone has the right to participate in decisions about energy, and that key stakeholders, including and especially those who are most vulnerable, should have a say in how energy is produced and consumed.',\n",
       " 'Time taken to get the response: 6.044 seconds')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatGPT(\"What does energy justice mean?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5717e1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07426f272e5d442d83bcbf07fe7abf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Prompt:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d083da7701ed4cc3bddc977408ed02bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model:', options=('text-davinci-003', 'text-ada-001', 'gpt-3.5-turbo', 'gpt-4'), value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbad7555dd33405c87e1b2044b4b51c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3889d60a94e3417d9518aafbff0152d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# Create widgets\n",
    "prompt_widget = widgets.Textarea(value='',\n",
    "                                 placeholder='Type something',\n",
    "                                 description='Prompt:',\n",
    "                                 disable=False)\n",
    "\n",
    "model_widget = widgets.Dropdown(options=['text-davinci-003', 'text-ada-001', 'gpt-3.5-turbo', 'gpt-4'],\n",
    "                                value='text-davinci-003',\n",
    "                                description='Model:',\n",
    "                                disable=False)\n",
    "\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# Function to be executed on button click\n",
    "def on_button_clicked(b):\n",
    "    with output_widget:\n",
    "        output_widget.clear_output()  # clear the output area each time the button is clicked\n",
    "        output, elapsed_time = chatGPT(prompt_widget.value, model_widget.value)\n",
    "        print(output)\n",
    "        print('-'*100)\n",
    "        print(elapsed_time)\n",
    "\n",
    "# Create a button\n",
    "button = widgets.Button(description=\"Generate Text\")\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(prompt_widget, model_widget, button, output_widget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4015ecf",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Transformers <a name=\"transformers\"></a>\n",
    "\n",
    "Transformers are a type of model architecture used in the field of Machine Learning, particularly for tasks involving natural language processing (NLP). Introduced in the seminal paper \"Attention is All You Need\" by Vaswani et al., the Transformer model revolutionized NLP by effectively dealing with the challenges of understanding the context and meaning in language data. The key innovation of Transformers is the mechanism called \"attention,\" which allows the model to weigh the importance of different words in a sentence when generating a prediction. Unlike previous methods that processed words in a sequence one after another, Transformers can process all words in a sentence simultaneously, making them more efficient and capable of capturing complex patterns in language. \n",
    "\n",
    "LLMs like GPT-3 and BERT are based on the transformer\n",
    "architecture. These models have many millions, or even billions, of parameters\n",
    "that are trained on large amounts of text data and they have set new standards in tasks like text generation, translation, and question answering. \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install transformers library\n",
    "%pip install transformers\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e02c1",
   "metadata": {},
   "source": [
    "\n",
    "Remember to import the necessary libraries at the start of your notebook:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e723bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of transformers: 4.30.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(f\"Version of transformers: {transformers.__version__}\")\n",
    "from transformers import pipeline\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acde912",
   "metadata": {},
   "source": [
    "\n",
    "## 3. HuggingFace's Transformers Library <a name=\"huggingface\"></a>\n",
    "\n",
    "From Transformers [website](https://huggingface.co/transformers):\n",
    "\n",
    "HuggingFace Transformers is a Python library that provides state-of-the-art pre-trained models for natural language processing (NLP) and natural language generation (NLG). The library includes models for a wide range of tasks, such as text classification, question answering, summarization, translation, and text generation.\n",
    "\n",
    "Transformers is built on top of PyTorch and TensorFlow, and it provides APIs that make it easy to download, load, and use pre-trained models. The library also includes a number of tools for fine-tuning pre-trained models for specific tasks, and for evaluating the performance of models.\n",
    "\n",
    "HuggingFace Transformers is a popular library for NLP and NLG research. It is used by a wide range of researchers and developers, and it is supported by a large community of contributors.\n",
    "\n",
    "Here are some of the features of HuggingFace Transformers:\n",
    "\n",
    "* A wide range of pre-trained models: Transformers includes models for a wide range of NLP and NLG tasks, in over 100 languages.\n",
    "* Easy to use APIs: The library provides APIs that make it easy to download, load, and use pre-trained models.\n",
    "* Tools for fine-tuning: Transformers includes tools for fine-tuning pre-trained models for specific tasks.\n",
    "* A large community: Transformers is a popular library with a large community of contributors.\n",
    "\n",
    "If you are interested in NLP or NLG research, then HuggingFace Transformers is a great library to use. It provides a wide range of pre-trained models, easy to use APIs, and tools for fine-tuning models.\n",
    "\n",
    "Here are some links to learn more about HuggingFace Transformers:\n",
    "\n",
    "* Documentation:        https://huggingface.co/docs/transformers/index\n",
    "* GitHub repository:    https://github.com/huggingface/transformers        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c906a45",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Using LLMs with the Transformers Library <a name=\"example\"></a>\n",
    "\n",
    "For an example project, we could demonstrate how to use the ChatGPT model with the Transformers library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be3e50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the USA is the great American city known as Baltimore, where it is the oldest, richest city in the country. In the United States the City of Baltimore has been known as the \"Great Capital of the World.\"\n",
      "\n",
      "\n",
      "The City\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the GPT-2 model\n",
    "gpt2 = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Use the model to generate a response\n",
    "response = gpt2('The capital of the USA is', max_length=50)\n",
    "\n",
    "print(response[0]['generated_text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('energy_justice')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "44e5a0b352bb81bb64b08912c126ba184b85b2b3fe908e7640b1e49d3d6685b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
